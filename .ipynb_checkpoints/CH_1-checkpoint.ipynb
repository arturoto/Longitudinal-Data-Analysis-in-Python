{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "#### 1.1 Advantages of Longitudinal Studies:\n",
    "\n",
    "Longitudinal methods help because:\n",
    "\n",
    "* To achieve similar level of stat power, fewer subject are needed.\n",
    "* reapeated nature of study makes the diviations of individual subjects more significant.\n",
    "\n",
    "* each subject serves as his/her own control\n",
    "\n",
    "* Statistical estimates of individual trends can be used to better understand heterogeneity in the population and the determinants of growth and change at the level of the individual.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 2 CHALLENGES OF LONGITUDINAL DATA ANALYSIS:\n",
    "\n",
    "* Observations are not, by definition, independent and we must account for the dependency in data using more sophisticated statistical methods.\n",
    "\n",
    "\n",
    "\n",
    "* Often, there is a lack of available computer software for application of these more complex statistical models, or the level of statistical sophistication required of the user is beyond the typical level of the practitioner. In certain cases, for example nonlinear models for binary, ordinal, or nominal endpoints, parameter estimation can be computationally intensive due to the need for numerical or Monte Carlo simulation methods to evaluate the likelihood of nonlinear mixed-effects regression models.\n",
    "\n",
    "* more likely that there are missing data due to attrition\n",
    "* the values of the predictors or independent variables can also change over time\n",
    "\n",
    "* \"The treatment of time-varying covariates in analysis of longitudinal data permits much stronger statistical inferences about dynamical relationships than can be obtained using cross-sectional data. The price, however, is considerable added complexity to the statistical model.\"\n",
    "\n",
    "* \"repeated measurements involve different conditions that the same subjects are exposed to. A classic example is a crossover design in which two or more treatments are given to the same subject in different orders\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 SOME GENERAL NOTATION\n",
    "\n",
    "N subjects in the longitudinal study as:\n",
    "$$ i = 1, ..., N \\hspace{.1cm} subjects$$\n",
    "measurement occasions as:\n",
    "$$ j = 1, ..., n \\hspace{.1cm} observations$$\n",
    "in the unbalanced case of unequal numbers of measurements or different time-points for different subjects:\n",
    " $$ j = 1, ..., n_i \\hspace{.1cm} observations \\hspace{.1cm} for \\hspace{.1cm} subject \\hspace{.1cm} i$$\n",
    " Total number of Observations\n",
    " $$ \\sum_{i}^{N}{n_i} $$\n",
    "The repeated responses, or outcomes, or dependent measures for subject $i$ are denoted as\n",
    "the vector:\n",
    "$$\\mathbf{y_i} = n_i \\times 1 $$\n",
    "The values of the p predictors, or covariates, or independent variables for subject $i$ on\n",
    "occasion $j$ are denoted as(includingan intercept term):\n",
    "$$\\mathbf{x_{ij}} = p \\times 1$$\n",
    "For time-invanant predictors (between subject, e.g., sex), the values of xt3are constant for j = 1,, ..,n,. For time-varying predictors (within-subject, e.g., age), the x,]can take on subject- and timepoint-specific values. To describe the entire matrix of predictors for subject 2, we use the notation\n",
    "$$\\mathbf{X_i} = n_i \\times p$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 DATA LAYOUT\n",
    "\n",
    "![title](Screen%20Shot%202018-06-29%20at%2012.54.33%20AM.png)\n",
    "\n",
    "\"The above layout depicts what is called a 2-level design in the multilevel [Goldstein, 199.51and hierarchical linear modeling [Raudenbush and Bryk, 20021literatures. Namely, repeated observations at level 1 are nested within subjects at level 2. In some cases,\n",
    "subjects themselves are nested within sites, hospitals, clinics, workplaces, etc.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 ANALYSIS CONSIDERATIONS\n",
    "\n",
    "There are several different features of longitudinal studies that must be considered when selecting an appropriate longitudinal analysis:\n",
    "\n",
    "1. form of the outcome or response measure:\n",
    "    * continuous and normally distributed(e.g.,a mixed-effects linear regression model)\n",
    "    * continuous but does not have a normal distribution( e.g.,acount), then alternative nonlinear models ( e.g., a mixed-effects Poisson regression model)\n",
    "    * For qualitative outcomes,such as binary(yes or no),ordinal( e.g.,sad,neutral, happy), or nominal (republican, democrat, independent), more complex nonlinear models are also typically required.\n",
    "    \n",
    "2. number of subjects $N$:\n",
    "    * The more advanced models ( e.g., generalized mixed-effects regression models) that are appropriate for analysis of unbalanced longitudinal data are based on large sample theory and may be inappropriate for analysis of small N studies (e.g.,N < 50).\n",
    "\n",
    "3. number of observations per subject $n_i$:\n",
    "    * When $n_i = n$ for all subjects, the design is said to be balanced, and traditional ANOVA or MANOVA models for repeated measurements ( i.e., traditional mixed-effects models or multivariate growth curve models) can be used. \n",
    "    * In the most general case where $n_i$ varies from subject to subject, more general methods are required ( e.g., generalized mixed-effects regression models)\n",
    "\n",
    "4. number and type of covariates is an important consideration for model selection for $E(\\mathbf{y_i})$\n",
    "\n",
    "5. selection of a plausible variance-covariance structure for the $V(\\mathbf{y_i})$:\n",
    "    * Different model specificationslead to\n",
    "        - (a) homogeneous or heterogeneous variances\n",
    "        - (b) homogeneous or heterogeneous covariances of the repeated measurements over time.\n",
    "    * Residual autocorrelation among the responses may also play a role in modeling the variance-ccwariance structure of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 GENERAL APPROACHES\n",
    "\n",
    "\n",
    "1. “derived variable” approach:\n",
    "    * reduction of the repeated measurements into a summary variable. Once reduced, this approach is strictly not longitudinal, a t-test is fine.\n",
    "    * Examples of derived variables include \n",
    "        - (a) average across time\n",
    "        - (b) linear trend across time, \n",
    "        - (c) carrying the last observation forward, \n",
    "        - (d) computing a change score, and\n",
    "        - (e) computing the area under the curve.\n",
    "    * In the unbalanced case ( e.g., drop-outs) therefore violate homoscedasticity.\n",
    "    *  reducing multiple repeated measurements to a single summary measurement: substantial loss of statistical power.\n",
    "\n",
    "2. ANOVA - Simple but most restrictive\n",
    "    * The model assumes compound symmetry which implies constant variances and covariances over time.\n",
    "    * Subjects don't always deviate from only baseline.\n",
    "3. MANOVA\n",
    "    * In the multivariate case, the repeated observations are generally trans- formed to orthogonal polynomial coefficients, and these coefficients ( eg., constant, linear, quadratic growth rates) are then used as multivariate responses in a MANOVA.\n",
    "    * does not permit missing data or different measurement occasions for different subjects.\n",
    "4. generalized mixed-effects regression models - widely used for analysis of longitudinal data (“full-likelihood”)\n",
    "\n",
    "    * can be applied to both normally distributed continuous outcomes as well as categorical outcomes and other nonnormally distributed outcome\n",
    "    *  robust to missing data and irregularly spaced measurement occasions and can easily handle both time-invariant and time-varying covariates\n",
    "    * The disadvantage: methods are more computationally complex\n",
    "    \n",
    "5. covariance pattern models\n",
    "    * variance-cwariance matrix of the repeated outcomes is modeled directly, and there is no attempt at distinguishing within-subjects variance from between-subjects variance\n",
    "    \n",
    "    \n",
    "6. GEE Models - general and computationally convenient alternative to mixed-effects regression models\n",
    "    * Disadvantage: missingdataareonlyignorableif the missing data are explained by covariates in the model. (A little restrictive)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.7 THE SIMPLEST LONGITUDIN ALANALYSIS\n",
    "\n",
    "Single group, two measurement occassions. \n",
    "\n",
    "A paired t-test can be used to determine if there is significant average change between two timepoints.\n",
    "\n",
    "$N$ subjects\n",
    "\n",
    "$y_{i1}$ - pre-test measurement\n",
    "\n",
    "$y_{i2}$ - post-test measurement\n",
    "\n",
    "$d_i = y_{i2} - y_{i1}$ change in score for subject $i$\n",
    "\n",
    "Testing Difference $H_0:(\\mu_{y_2} - \\mu_{y_1}) = 0 $\n",
    "\n",
    "Test:\n",
    "    \n",
    "$t = \\frac{\\bar{d}}{{s_d} / \\sqrt{N}}$\n",
    "\n",
    "$ = \\frac{\\bar{d}}{\\sqrt{[\\sum_{i}{d_i^2} - \\frac{(\\sum_{i}{d_i})^2}{N}] / (N-1)}/\\sqrt{N}}$\n",
    "\n",
    "Same test can be done using a regression model:\n",
    "\n",
    "$d_i = \\beta_0 + e_i$\n",
    "\n",
    "Assuming Normality, we can test $H_0 : \\beta_0 = 0$ bu computing a ratio of $\\hat{\\beta_0}$ to its $SE$. (t-distribution with N-1 degrees of freedom)\n",
    "\n",
    "\n",
    "### 1.7.1 Change Score Analysis\n",
    "\n",
    "Slightly more comlex randomized subjects into two groups:\n",
    "\n",
    "$x_i = 1$ - treatment \n",
    "\n",
    "$x_i = 0$ -  control\n",
    "\n",
    "A regression model for the change score:\n",
    "\n",
    "$d_i = \\beta_0 + \\beta_1 x_i + e_i$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\beta_0$ - Average $\\Delta$ for control group\n",
    "\n",
    "$\\beta_1$ - Difference in Avg change between the two groups\n",
    "\n",
    "Hypothesis testing is as follows:\n",
    "\n",
    "$H_0 : \\beta_0 = 0$ test whether the avg change is == 0 for control\n",
    "\n",
    "$H_0: \\beta_1 = 0$ test whether avg change is equal fot the two groups\n",
    "\n",
    "\n",
    "Note: Change score analysis is == to regressing on the post-treatment var's with treatment var:\n",
    "\n",
    "$d_i = \\beta_0 + \\beta_1 x_i + e_i$\n",
    "\n",
    "$y_{i2} - y_{i1} = \\beta_0 + \\beta_1 x_i + e_i$\n",
    "\n",
    "$y_{i2} = y_{i1} + \\beta_0 + \\beta_1 x_i + e_i$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.7.2 Analysis of Covariance of Post-test Scores\n",
    "\n",
    "When the slope describing the relationship between the pre-test and post-test score is not one, then we have an ANCOVA:\n",
    "\n",
    "$y_{i2} = \\beta_0 + \\beta_1 x_i + \\beta_2y_{i1} + e_i$\n",
    "\n",
    "The Hypothesis tests now become:\n",
    "\n",
    "$H_0 : \\beta_0 = 0$ average post-test is equal to zero for the control group subjects with zero pre-test\n",
    "\n",
    "$H_0: \\beta_1 = 0$ post-test is equal for the two groups, given the same value on the pre-test\n",
    "\n",
    "$H_0: \\beta_2 = 0$ post-test is related to the pre-test, conditional on group\n",
    "\n",
    "Note: If subjects are randomized to group, then ANCOVA is more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.7.4 Example\n",
    "\n",
    "Applying to Television School and Family Smoking Prevention and Cessation Project\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193    193101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193    193101     0     0     5  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193    193101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>193    193101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193    193101     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>193    193101     0     0     4  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>193    193101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>193    193101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>193    193101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>193    193101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>193    193101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>193    193101     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>193    193101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>194    194101     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>194    194101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>194    194101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194    194101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>194    194101     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>194    194101     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>194    194101     0     0     4  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>194    194101     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>194    194101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>194    194101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>194    194101     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>194    194102     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>515    515111     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>515    515111     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>515    515111     0     0     4  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>515    515111     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>515    515111     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>515    515111     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>515    515111     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>515    515111     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>515    515111     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>515    515112     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>515    515112     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>515    515112     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>515    515112     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>515    515112     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>515    515112     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>515    515113     0     0     0  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>515    515113     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>515    515113     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>515    515113     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>515    515113     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>515    515113     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>515    515113     0     0     1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>515    515113     0     0     2  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>515    515113     0     0     3  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>515    515113     0     0     3  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                  193    193101     0     0     3  ...\n",
       "1                  193    193101     0     0     1  ...\n",
       "2                  193    193101     0     0     5  ...\n",
       "3                  193    193101     0     0     1  ...\n",
       "4                  193    193101     0     0     3  ...\n",
       "5                  193    193101     0     0     2  ...\n",
       "6                  193    193101     0     0     0  ...\n",
       "7                  193    193101     0     0     3  ...\n",
       "8                  193    193101     0     0     4  ...\n",
       "9                  193    193101     0     0     2  ...\n",
       "10                 193    193101     0     0     2  ...\n",
       "11                 193    193101     0     0     3  ...\n",
       "12                 193    193101     0     0     2  ...\n",
       "13                 193    193101     0     0     3  ...\n",
       "14                 193    193101     0     0     1  ...\n",
       "15                 193    193101     0     0     2  ...\n",
       "16                 193    193101     0     0     0  ...\n",
       "17                 193    193101     0     0     3  ...\n",
       "18                 194    194101     0     0     3  ...\n",
       "19                 194    194101     0     0     1  ...\n",
       "20                 194    194101     0     0     2  ...\n",
       "21                 194    194101     0     0     2  ...\n",
       "22                 194    194101     0     0     0  ...\n",
       "23                 194    194101     0     0     0  ...\n",
       "24                 194    194101     0     0     4  ...\n",
       "25                 194    194101     0     0     2  ...\n",
       "26                 194    194101     0     0     1  ...\n",
       "27                 194    194101     0     0     1  ...\n",
       "28                 194    194101     0     0     1  ...\n",
       "29                 194    194102     0     0     2  ...\n",
       "...                                                 ...\n",
       "1514               515    515111     0     0     3  ...\n",
       "1515               515    515111     0     0     2  ...\n",
       "1516               515    515111     0     0     4  ...\n",
       "1517               515    515111     0     0     3  ...\n",
       "1518               515    515111     0     0     3  ...\n",
       "1519               515    515111     0     0     2  ...\n",
       "1520               515    515111     0     0     2  ...\n",
       "1521               515    515111     0     0     0  ...\n",
       "1522               515    515111     0     0     3  ...\n",
       "1523               515    515112     0     0     2  ...\n",
       "1524               515    515112     0     0     1  ...\n",
       "1525               515    515112     0     0     1  ...\n",
       "1526               515    515112     0     0     3  ...\n",
       "1527               515    515112     0     0     2  ...\n",
       "1528               515    515112     0     0     3  ...\n",
       "1529               515    515112     0     0     2  ...\n",
       "1530               515    515112     0     0     2  ...\n",
       "1531               515    515112     0     0     2  ...\n",
       "1532               515    515112     0     0     2  ...\n",
       "1533               515    515112     0     0     3  ...\n",
       "1534               515    515113     0     0     0  ...\n",
       "1535               515    515113     0     0     3  ...\n",
       "1536               515    515113     0     0     3  ...\n",
       "1537               515    515113     0     0     3  ...\n",
       "1538               515    515113     0     0     2  ...\n",
       "1539               515    515113     0     0     2  ...\n",
       "1540               515    515113     0     0     1  ...\n",
       "1541               515    515113     0     0     2  ...\n",
       "1542               515    515113     0     0     3  ...\n",
       "1543               515    515113     0     0     3  ...\n",
       "\n",
       "[1544 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wget https://content.sph.harvard.edu/fitzmaur/ala/tvsfp.txt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['School_ID', 'Class_ID', 'School_based_Resistance_Curriculum(1=yes,0=no)', \\\n",
    "          'Television_based_Prevention_Program(1=yes,0=no)', 'Pre_interventions_THKS_score', \\\n",
    "          'Post_interventions_THKS_score']\n",
    "\n",
    "tel_data = pd.read_csv('tvsfp.txt',delimiter='\\t', skiprows= 100, header=None)\n",
    "\n",
    "tel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
