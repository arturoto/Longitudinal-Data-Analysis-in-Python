{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MANOVA Approaches to Longitudinal Data\n",
    "\n",
    "\n",
    "The primary advantage of the MANOVA approach versus the ANOVA approach is that the MANOVA assumes a general form for the correlation of repeated measurements over time, whereas the ANOVA assumes the much more restrictive compound-symmetric form. \n",
    "\n",
    "The disadvantage of the MANOVA model is that it requires complete data. Subjects with incomplete data must be removed from the analysis, leading to potential bias, or have their missing values imputed in some way. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MANOVA for Repeated Measures\n",
    "\n",
    "For $n$ repeated measures the response vector $\\textbf{y}_i$ is a matrix of $(n x 1)$.\n",
    "A one-sample MANOVA model:\n",
    "\n",
    "$$\\textbf{y}_i = \\pmb{\\mu} + \\pmb{\\epsilon}_i$$\n",
    "\n",
    "where \n",
    "\n",
    "$\\pmb{\\mu} = (n x 1)$ vector of means at different time points\n",
    "\n",
    "$\\pmb{\\epsilon}_i = (n x 1)$ vector of errors $\\sim N(0, \\pmb{\\Sigma})$\n",
    "\n",
    "Note: the error variance covatiance matrix is allowed to be completly general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Growth Curve Analysis - Polynomial Representation\n",
    "\n",
    "The mean vector of the polynomial growth-curve model can be characterized as:\n",
    "\n",
    "![](./MANOVA_SF/Screen Shot 2018-07-04 at 11.20.18 AM.png)\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "$t_1, t_2, ..., t_n$ Represent the timepoint values\n",
    "\n",
    "$q <= n$ represents the degree of the polynomial\n",
    "\n",
    "\n",
    "Generally useful to orthogonalize $\\textbf{T}$ as $\\pmb{\\mu} = \\textbf{P}'\\pmb{\\theta}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\textbf{P}$ is the matrix of orthogonal polynomials\n",
    "\n",
    "\n",
    "\n",
    "The orthogonal polynomial trend model:\n",
    "\n",
    "$$\\textbf{Py}_i = \\textbf{P}\\pmb{\\mu} + \\textbf{P}\\pmb{\\epsilon}_i$$\n",
    "$$= \\pmb{\\theta} + \\pmb{\\epsilon_i^*}$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\pmb{\\theta}$ is a n x 1 vector of transformed population mean and \n",
    "$\\pmb{\\hat{\\theta}} = \\textbf{P}\\pmb{\\bar{y}}_.$\n",
    "\n",
    "$\\pmb{\\epsilon_i^*} \\sim N(0, \\pmb{\\Sigma^*} = \\pmb{P \\Sigma P}')$\n",
    "\n",
    "\n",
    "The MANOVA table, with SSCP denoting a sum of squares and cross-product matrix:\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%2011.36.45%20AM.png)\n",
    "\n",
    "Where\n",
    "\n",
    "$\\textbf{Y}$ is the (N x n) matrix of all data\n",
    "\n",
    "\n",
    "\n",
    "The orthogonal polynomial partition of sum of squares and products is:\n",
    "\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%2011.39.28%20AM.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extracting Univariate Repeated Measures ANOVA Results\n",
    "\n",
    "If Sphericity holds then:\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%2011.41.58%20AM.png)\n",
    "\n",
    "The SS quantities are obratined from the $SST^*$ and $SSR^*$ matricies. The $MS$ quantities for the F-test are obtained by deviding $MS_R$\n",
    "\n",
    "$$MS_R = \\frac{\\sum_{1}^n{SSR_{diagonal}^*}}{(N-1)(n-1)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Test of the Time Effect\n",
    "\n",
    "In order to test the null hypothesis of no effect of time, $H_o: \\mu$ elements are all equal such that $H_o: \\tau = 0$, we must extract and compare the lower ( n- 1) x ( n- 1) submatrices of $SST^*$ and $SSR^*$\n",
    "\n",
    "\n",
    "To the extent that there is a time effect, and the null hypothesis is not true, the time $SST^*$ submatrix will contain larger elements than the residual $SSR^*$ submatrix so:\n",
    "\n",
    "$$ | SST_{n-1}^* - \\lambda SSR_{n-1}^*| = 0$$\n",
    "\n",
    "which has one nonzero latent root or eigenvalue $\\lambda_1$ , Note that this latent root equals one if $SST_{n-1}* = SSR_{n-1}^*$. Thus, to the extent that the null hypothesis is true, the latent root will e approximatelyequal to one.\n",
    "\n",
    "The above equation can be simplified to a one-matrix eigenproblem using the Cholesky factorization $SSR_{n-1}^* = \\textbf{E}\\textbf{E}'$\n",
    "\n",
    "$$\\mid\\textbf{E}^{-1} SST_{n-1}^*(\\textbf{E}^{-1})' - \\lambda\\textbf{I}_{n-1}\\mid = 0$$\n",
    "\n",
    "Overall test statistics for the null hypothesis of no time effect include Roy’s largest root statistic(the eigenvalue $\\lambda_1$),and Wilk’s Lambda $(\\Lambda = \\frac{1}{(1+\\lambda_1)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests of Specific Time Elements\n",
    "\n",
    "If sphericity is reasonable and the univariate repeated measures ANOVA :\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%2012.30.27%20PM.png)\n",
    "\n",
    "If sphericity is rejected and a MANOVA is performed then:\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%2012.32.21%20PM.png)\n",
    "\n",
    "\n",
    "in general, the univariate repeated measures model tests( assuming sphericity) of the trend components, which use the pooled error term, are more powerful than the corresponding tests under the MANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANOVA of Repeated Measures - A Sample Case\n",
    "\n",
    "let \n",
    "\n",
    "$h = 1, ..., s$ groups\n",
    "\n",
    "$i = 1, ..., N_h$ subjects in each group\n",
    "\n",
    "$j = 1, ..., n$ timepoints\n",
    "\n",
    "$N = \\sum{N_h}$\n",
    "\n",
    "The model is written as:\n",
    "\n",
    "$$\\textbf{y}_{hi} = \\pmb{\\mu} + \\pmb{\\gamma}_h + \\pmb{\\epsilon}_{hi}$$\n",
    "\n",
    "where \n",
    "\n",
    "$\\pmb{\\mu}$ is the n x 1 vector of timepoint means\n",
    "\n",
    "\n",
    "$\\pmb{\\gamma}_h$ is the n x 1 vector effect for the population from which the $h^{th}$ group of subjects was drawn\n",
    "\n",
    "$\\pmb{\\epsilon}_{hi}$ is the n x 1 vector of errors distributed as N ( 0 ,X) in each of the populations\n",
    "\n",
    "The model assumes homogeneity of variance-covatiance accross the $s$ groups (the general error variance-covariance matrix $\\sum$ for all $s$ groups)\n",
    "\n",
    "Model with orthogonal transformation for the time effects:\n",
    "\n",
    "\n",
    "\n",
    "$$\\textbf{P}\\textbf{y}_{hi} = \\textbf{P}\\pmb{\\mu} + \\textbf{P}\\pmb{\\gamma}_h + \\textbf{P}\\pmb{\\epsilon}_{hi}$$\n",
    "\n",
    "with \n",
    "\n",
    "$\\epsilon_{hi} \\sim N(0,\\pmb{\\Sigma^*} = \\textbf{P} \\Sigma \\textbf{P}')$\n",
    "\n",
    "\n",
    "The resulting MANOVA table is given by\n",
    "\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%201.24.29%20PM.png)\n",
    "\n",
    "Under the present orthogonal polynomial parameterization of the model $P$. The information in the cross-product matrices:\n",
    "\n",
    "\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%201.26.33%20PM.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Univariate Repeated Measures ANOVA Results\n",
    "\n",
    "ANOVA :\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%201.29.11%20PM.png)\n",
    "\n",
    "F-test for ANOVA:\n",
    "\n",
    "![](./MANOVA_SF/Screen%20Shot%202018-07-04%20at%201.30.26%20PM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Tests\n",
    "\n",
    "Testinf for the overall time and group x time effects invlove multivariate tests. They are obtained by extracting the (n - 1) x (n - 1)submatricies of $SSG^*$ and $SSR^*$, and solving the deteminantial equations of min(s - 1, n - 1) latent roots:\n",
    "\n",
    "$$\\mid SST_{n-1}^* - \\lambda SSR_{n-1}^* \\mid = 0$$\n",
    "\n",
    "Wilk’s Lambda is computed as:\n",
    "\n",
    "$$\\Lambda = \\prod_{h = 1}^{s - 1} \\frac{1}{(1 + \\lambda_h)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.670820</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>-0.670820</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.500000  0.500000  0.500000  0.500000\n",
       "1 -0.670820 -0.223607  0.223607  0.670820\n",
       "2  0.500000 -0.500000 -0.500000  0.500000\n",
       "3 -0.223607  0.670820 -0.670820  0.223607"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "testing_DF = pd.DataFrame({'t1':[1, 0, 0, 0], \\\n",
    "                          't2':[1, 1, 1, 1], \\\n",
    "                          't3':[1, 2, 4, 8], \\\n",
    "                          't4':[1, 3, 9, 27]})\n",
    "\n",
    "\n",
    "\n",
    "np_arr = testing_DF.values\n",
    "time = np_arr\n",
    "# P already Normalized\n",
    "pd.DataFrame(np.dot(np.linalg.inv(np.linalg.cholesky(np.dot(time, time.T)).T).T, time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('./Datasets/VocabGrowth.csv', \\\n",
    "                   names = ['8_Grade', '9_Grade', '10_Grade', '11_Grade'])\n",
    "VocabGrowth = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8_Grade     1.137500\n",
       "9_Grade     2.541719\n",
       "10_Grade    2.988281\n",
       "11_Grade    3.468750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bar_dot = VocabGrowth.mean()\n",
    "y_bar_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.670820</td>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.223607</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>-0.670820</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.500000  0.500000  0.500000  0.500000\n",
       "1 -0.670820 -0.223607  0.223607  0.670820\n",
       "2  0.500000 -0.500000 -0.500000  0.500000\n",
       "3 -0.223607  0.670820 -0.670820  0.223607"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Orthoginal Matrix\n",
    "# P already Normalized\n",
    "P = pd.DataFrame(np.dot(np.linalg.inv(np.linalg.cholesky(np.dot(time, time.T)).T).T, time))\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.068125  ,  1.66370445, -0.461875  ,  0.22172012])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Orthogonal Polynomial Estimates\n",
    "np.dot(P, y_bar_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 307.8958,  386.1704,  441.3901,  432.475 ],\n",
       "       [ 386.1704,  687.3115,  709.6184,  755.9904],\n",
       "       [ 441.3901,  709.6184,  867.8297,  876.6472],\n",
       "       [ 432.475 ,  755.9904,  876.6472, 1003.9108]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y is the (N x n) matrix of all data\n",
    "Y = VocabGrowth\n",
    "Yt_Y = np.dot(Y.T, Y)\n",
    "Yt_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1837.842678125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)*np.dot(y_bar_dot, y_bar_dot.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4833.4880125 ,   543.32773521,  -199.40535   ,    48.2887824 ],\n",
       "       [  543.32773521,   227.51182   ,   -37.09949824,    20.46799   ],\n",
       "       [ -199.40535   ,   -37.09949824,    57.6846    ,   -10.63663996],\n",
       "       [   48.2887824 ,    20.46799   ,   -10.63663996,    63.86868   ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSR_r = np.dot(np.dot(P, np.subtract(Yt_Y, len(Y)*np.dot(y_bar_dot, y_bar_dot.T))), P.T)\n",
    "SSR_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.83784268e+03, -1.13686838e-13, -6.25277607e-13,\n",
       "         2.44426701e-12],\n",
       "       [-1.13686838e-13,  1.83784268e+03,  5.68434189e-13,\n",
       "        -2.04636308e-12],\n",
       "       [-6.25277607e-13,  5.68434189e-13,  1.83784268e+03,\n",
       "        -1.18234311e-11],\n",
       "       [ 2.44426701e-12, -2.04636308e-12, -1.17097443e-11,\n",
       "         1.83784268e+03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST_t = len(Y) * np.dot(np.dot(P, np.dot(y_bar_dot, y_bar_dot.T)), P.T)\n",
    "SST_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the multivariate test for the grade effect, the determinantal equation using the Cholesky factorization SSR Tn-l) = EE’, yields 4.7432 as Roy’s largest root statistic (eigenvalueor latent root XI ) .\n",
    "\n",
    "$$\\mid\\textbf{E}^{-1} SST_{n-1}^*(\\textbf{E}^{-1})' - \\lambda\\textbf{I}_{n-1}\\mid = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4833.4880125 ,   543.32773521,  -199.40535   ,    48.2887824 ],\n",
       "       [  543.32773521,   227.51182   ,   -37.09949824,    20.46799   ],\n",
       "       [ -199.40535   ,   -37.09949824,    57.6846    ,   -10.63663996],\n",
       "       [   48.2887824 ,    20.46799   ,   -10.63663996,    63.86868   ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSR_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.83784268e+03,  5.68434189e-13, -2.04636308e-12],\n",
       "       [ 5.68434189e-13,  1.83784268e+03, -1.18234311e-11],\n",
       "       [-2.04636308e-12, -1.17097443e-11,  1.83784268e+03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSR_n1 = SSR_r[1:, 1:]\n",
    "SST_n1 = SST_t[1:, 1:]\n",
    "SST_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.08349495,  0.        ,  0.        ],\n",
       "       [-2.45960889,  7.18574451,  0.        ],\n",
       "       [ 1.35697927, -1.01576137,  7.80996262]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.linalg.cholesky(SSR_n1)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06629763,  0.        ,  0.        ],\n",
       "       [ 0.02269302,  0.13916442,  0.        ],\n",
       "       [-0.00856775,  0.01809968,  0.12804159]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_inv = np.linalg.inv(E)\n",
    "E_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(len(SSR_n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.07800965,  2.76502237, -1.04393441],\n",
       "       [ 2.76502237, 36.53945562,  4.27188849],\n",
       "       [-1.04393441,  4.27188849, 30.8677672 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(E_inv, SST_n1), E_inv.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17411896, 0.        , 0.        ],\n",
       "       [0.        , 0.17411896, 0.        ],\n",
       "       [0.        , 0.        , 0.17411896]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/5.7432)* np.identity(len(SSR_n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17411896, 0.        , 0.        ],\n",
       "       [0.        , 0.17411896, 0.        ],\n",
       "       [0.        , 0.        , 0.17411896]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((1/5.7432), np.identity(len(SSR_n1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ident = np.multiply((4.7432), np.identity(len(SSR_n1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_det = np.subtract(np.dot(np.dot(E_inv, SST_n1), E_inv.T), ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450.20274893223"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(in_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $SSCP (n x n)$\n",
    "\n",
    "$$SST^* = \\textbf{P} SST \\textbf{P}' = N\\textbf{P} \\bar{\\textbf{y}_{..}}\\bar{\\textbf{y}_{..}}' \\textbf{P}'$$\n",
    "where $SST = \\bar{\\textbf{y}_{..}}\\bar{\\textbf{y}_{..}}'$\n",
    "\n",
    "$$SSG^* = \\textbf{P} SSG \\textbf{P}' = \\textbf{P}(\\sum_h N_h \\bar{\\textbf{y}_{..}} \\bar{\\textbf{y}_{..}}' - SST )\\textbf{P}'$$\n",
    "where $SSG = \\sum_h N_h \\bar{\\textbf{y}_{..}} \\bar{\\textbf{y}_{..}}' - SST $\n",
    "\n",
    "$$SSY^* = \\textbf{P} SSY \\textbf{P}' = \\textbf{P}(\\sum_h \\sum_i \\textbf{y}_{hi} \\textbf{y}_{hi}')\\textbf{P}'$$\n",
    "where $SSY = \\sum_h \\sum_i \\textbf{y}_{hi} \\textbf{y}_{hi}'$\n",
    "\n",
    "\n",
    "$$SSR^* = \\textbf{P} SSR \\textbf{P}' = \\textbf{P}(SSY - SSG - SST )\\textbf{P}'$$\n",
    "and $SSR = SSY - SST - SST$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.83784268e+03, -1.13686838e-13, -6.25277607e-13,\n",
       "         2.44426701e-12],\n",
       "       [-1.13686838e-13,  1.83784268e+03,  5.68434189e-13,\n",
       "        -2.04636308e-12],\n",
       "       [-6.25277607e-13,  5.68434189e-13,  1.83784268e+03,\n",
       "        -1.18234311e-11],\n",
       "       [ 2.44426701e-12, -2.04636308e-12, -1.17097443e-11,\n",
       "         1.83784268e+03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST = np.dot(y_bar_dot, y_bar_dot.T)\n",
    "SST_s = np.multiply(len(Y),np.dot(np.dot(P, SST), P.T))\n",
    "SST_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80912639e+03, -2.27373675e-13, -6.25277607e-13,\n",
       "         2.44426701e-12],\n",
       "       [-2.27373675e-13,  1.80912639e+03,  6.25277607e-13,\n",
       "        -1.98951966e-12],\n",
       "       [-6.25277607e-13,  6.82121026e-13,  1.80912639e+03,\n",
       "        -1.14823706e-11],\n",
       "       [ 2.44426701e-12, -2.04636308e-12, -1.14823706e-11,\n",
       "         1.80912639e+03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSG = np.subtract(np.multiply(len(Y), np.dot(y_bar_dot, y_bar_dot.T)), SST)\n",
    "SSG_s = np.dot(np.dot(P, SSG), P.T)\n",
    "SSG_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5513.5280343750455"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(SST_s[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
